{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from albumentations import VerticalFlip, HorizontalFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    '''\n",
    "    The load_data function takes the path of the dataset and gives you a list of images and masks path.\n",
    "    '''\n",
    "    images = sorted(glob(os.path.join(path, \"input_crop/\" + \"*.png\")))     \n",
    "    masks = sorted(glob(os.path.join(path, \"mask_crop/\" + \"*.png\")))\n",
    "    return images, masks\n",
    "\n",
    "path = \"/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/\"\n",
    "\n",
    "images, masks = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0071_1020.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0071_1021.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0071_1022.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0073_1030.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0074_1049.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0075_1054.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0077_1072.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0078_1073.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0078_1074.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0079_1084.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0080_1106.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0081_1108.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0081_1109.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0082_1116.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0082_1117.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0083_1123.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0083_1124.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0083_1125.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0084_1137.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0084_1138.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0085_1141.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset0_0087_1180.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0070_0997.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0071_1005.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0071_1006.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0071_1007.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0072_1028.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0072_1029.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0073_1044.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0073_1045.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0073_1046.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0073_1047.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0074_1056.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0075_1059.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0076_1062.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0076_1063.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0077_1066.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0078_1085.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0079_1090.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0080_1103.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0082_1121.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0084_1131.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0085_1152.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0086_1157.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0086_1158.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0087_1165.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset1_0088_1176.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0065_0812.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0065_0813.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0065_0814.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0065_0815.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0066_0835.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0069_0895.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0069_0896.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0071_0985.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0071_0986.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0072_0992.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0073_0994.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0076_1024.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0076_1025.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0076_1026.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0077_1050.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0079_1067.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0079_1068.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0085_1153.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0085_1154.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0086_1159.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0087_1160.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0088_1172.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0088_1173.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0088_1174.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset2_0088_1175.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0066_0901.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0066_0902.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0066_0903.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0066_0904.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0067_0905.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0067_0906.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0067_0907.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0069_0940.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0070_0954.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0071_0960.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0073_0972.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0074_0998.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0074_0999.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0075_1004.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0076_1040.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0077_1043.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0079_1051.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0081_1107.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0082_1119.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0083_1120.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0084_1171.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0087_1177.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0087_1178.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset3_0088_1179.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0079_1079.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0079_1080.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0080_1096.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0080_1097.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0081_1098.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0082_1101.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0083_1102.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0085_1110.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0085_1111.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0085_1112.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0085_1113.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0085_1114.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0085_1115.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0087_1132.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0087_1133.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0087_1134.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0087_1135.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0087_1136.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0088_1145.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0088_1146.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0088_1147.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0088_1148.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0088_1149.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0088_1150.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/input_crop/subset4_0088_1151.png']\n",
      "121\n",
      "['/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0071_1020.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0071_1021.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0071_1022.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0073_1030.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0074_1049.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0075_1054.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0077_1072.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0078_1073.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0078_1074.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0079_1084.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0080_1106.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0081_1108.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0081_1109.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0082_1116.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0082_1117.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0083_1123.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0083_1124.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0083_1125.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0084_1137.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0084_1138.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0085_1141.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset0_0087_1180.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0070_0997.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0071_1005.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0071_1006.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0071_1007.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0072_1028.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0072_1029.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0073_1044.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0073_1045.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0073_1046.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0073_1047.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0074_1056.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0075_1059.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0076_1062.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0076_1063.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0077_1066.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0078_1085.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0079_1090.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0080_1103.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0082_1121.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0084_1131.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0085_1152.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0086_1157.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0086_1158.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0087_1165.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset1_0088_1176.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0065_0812.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0065_0813.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0065_0814.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0065_0815.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0066_0835.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0069_0895.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0069_0896.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0071_0985.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0071_0986.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0072_0992.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0073_0994.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0076_1024.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0076_1025.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0076_1026.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0077_1050.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0079_1067.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0079_1068.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0085_1153.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0085_1154.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0086_1159.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0087_1160.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0088_1172.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0088_1173.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0088_1174.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset2_0088_1175.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0066_0901.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0066_0902.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0066_0903.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0066_0904.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0067_0905.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0067_0906.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0067_0907.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0069_0940.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0070_0954.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0071_0960.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0073_0972.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0074_0998.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0074_0999.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0075_1004.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0076_1040.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0077_1043.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0079_1051.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0081_1107.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0082_1119.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0083_1120.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0084_1171.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0087_1177.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0087_1178.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset3_0088_1179.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0079_1079.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0079_1080.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0080_1096.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0080_1097.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0081_1098.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0082_1101.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0083_1102.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0085_1110.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0085_1111.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0085_1112.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0085_1113.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0085_1114.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0085_1115.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0087_1132.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0087_1133.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0087_1134.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0087_1135.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0087_1136.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0088_1145.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0088_1146.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0088_1147.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0088_1148.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0088_1149.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0088_1150.png', '/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/data/mask_crop/subset4_0088_1151.png']\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "print(images)\n",
    "print(len(images))\n",
    "\n",
    "print(masks)\n",
    "print(len(masks))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new_data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_path = \"/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/new_data\"\n",
    "new_input_crop = \"/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/new_data/input_crop\"\n",
    "new_mask_crop = \"/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/new_data/mask_crop\"\n",
    "\n",
    "create_dir(new_data_path)\n",
    "create_dir(new_input_crop)\n",
    "create_dir(new_mask_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 512 \n",
    "W = 512 \n",
    "def augment_data(images, masks, augment, save_path):\n",
    "    for x, y in zip(images, masks):\n",
    "        \"\"\"\n",
    "        Extracting image and mask\n",
    "        \"\"\"    \n",
    "        image = x.split(\"/\")[-1].split(\".\")\n",
    "        image_name = image[0] # subset0_0071_1020\n",
    "        image_extn = image[1] # png\n",
    "        \n",
    "        mask = y.split(\"/\")[-1].split(\".\") # ['subset0_0071_1020', 'png']\n",
    "        mask_name = mask[0] # subset0_0071_1020\n",
    "        mask_extn = mask[1] # png\n",
    "        \n",
    "        \"\"\"\n",
    "        Read image and mask\n",
    "        \"\"\"\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR) \n",
    "        y = cv2.imread(y, cv2.IMREAD_COLOR) \n",
    "\n",
    "        \"\"\"\n",
    "        Augmentation\n",
    "        \"\"\"\n",
    "        if augment == True: \n",
    "            aug = HorizontalFlip(p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x1 = augmented['image']\n",
    "            y1 = augmented['mask']\n",
    "            \n",
    "            aug = VerticalFlip(p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x2 = augmented['image']\n",
    "            y2 = augmented['mask']\n",
    "            \n",
    "            save_images = [x, x1, x2]\n",
    "            save_masks  = [y, y1, y2]\n",
    "                \n",
    "        else: \n",
    "            save_images = [x]\n",
    "            save_masks = [y]\n",
    "        \n",
    "        \"\"\"\n",
    "        Saving the image and mask.\n",
    "        \"\"\"\n",
    "        idx = 0 \n",
    "        for i, m in zip(save_images, save_masks):\n",
    "            i = cv2.resize(i, (H, W))\n",
    "            m = cv2.resize(m, (H, W))\n",
    "            \n",
    "            tmp_image_name = f\"{image_name}_{idx}.{image_extn}\"\n",
    "            tmp_mask_name = f\"{mask_name}_{idx}.{mask_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, \"input_crop\", tmp_image_name)\n",
    "            mask_path = os.path.join(save_path, \"mask_crop\", tmp_mask_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "            cv2.imwrite(mask_path, m)\n",
    "            \n",
    "            idx += 1             \n",
    "save_path = \"/home/thanh/workspace/intern/Data-Augmentation-for-Semantic-Segmentation-Dataset/new_data\"            \n",
    "augment_data(images=images, masks=masks, augment=True, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
